
This files describes the logic I have followed to solve this question

###:
	1. Limit-book:
                a. Level of limit book starts from 0. If a incoming packet of level 1, is getting inserted into the limit book of SIZE 0, automatically that data will appear at level 0
                    of the limit book.( Because there are no data at level-0 of limit book)
		b. The price of buy side will be in decreasing order and increasing order for sell side.
       		c. There must be unique price in each side(buy&sell) of limit book.
		INSERT: after inserting a new value in the limit book. Delete all the price in  the book which violating the
			   book property.
			   Example: Suppose following is the initial limit book.
			   COUNT@PRICET
			   101@100
			   99@99
			   12@98
			   #a new packet comes with price 97 and count 100 and level 1..following is the updated book
			   101@100
			   100@97
			   
			   Price 98 deleted because it's violating the limit book property.
	        UPDATE: If incoming packet's level is less than or equal to the size of the book, then update the value.
		        Else insert this new data. And do the same limit property check.
		DELETE: if incoming packet's level is present in the limit book, then check the price..if both have same price and quantity
		        then perform delete operation.
			ELSE search the limit book for the price which we want to delete and then if both has same price and quantity then do delete.
			#if there is a mismatch in quantity, keep the extra positive quantity in the book.
		
		CROSSED BOOK: When the order book is part of a matching engine, orders are matched as the interest of buyers and sellers 
		can be satisfied. When there are orders where the bid price is equal or higher than the lowest ask, 
		those orders can be immediately fulfilled and will not be part of the open orders book(source WIKI). Have implemented
		this logic too.

	2. Serialize and Deserialize packet:
		To limit the size of on the fly network packet, serialization and deserialization of data has been implemented.
		The logic is based upon Google Protocol Buffer concept. Rather using the protobuf lib, I have written few lines
		of code which will serialize and deserialize the limited datatypes, required by this application. Obviously it will speed up 
		the network communication.
	
	

###Architecture:
	Please see the archi.png file to get pictorial representation of architecture.
	(1) Server architecture is simple like a server-client model. Server reading packets from the file system and
	sending to client after serializing it.
	(2) As we are using UDP for network level communication. We know that UDP is not reliable, but it speeds up the communication process.
	 As TCP has ACK mechanism(sliding window concept), which doesn't allow any packet loss, but  compare to UDP,  TCP communication is slow.
	 To minimize the rate of packet loss, I have developed two dedicated thread for client. Thread-1 reads data from network and push it in
	 a shared queue. Thread-2 reads data from shared queue and maintains the limit book. This architecture is similar like Kernel's Top half 
	 and bottom half concept. As Thread-1 is simply reading data from network and storing into a shared queue, hence the rate of packet loss will be less.
	(3) Have used select to wait for incoming data. Ref "man select"


#If my assumptions about limit book is wrong, then my solution is also wrong. 
#
#An attempt to retrive UDP lost packet in experiment branch...file server_lookup.cpp
